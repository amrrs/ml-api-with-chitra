{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fastest way to create an ML API with Chitra",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGHoJXbPu6eL"
      },
      "outputs": [],
      "source": [
        "pip install -U \"chitra[serve]\" -q "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install tornado==4.5.3"
      ],
      "metadata": {
        "id": "OLk_vjJE0AxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers -q "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2r99qNrvYV2",
        "outputId": "5c4c6fc2-2eb6-4ff0-ff7e-bd63e7e34f2a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.8 MB 22.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 49.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 64.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n"
      ],
      "metadata": {
        "id": "oylBvQu1vCjC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from chitra.serve import create_api"
      ],
      "metadata": {
        "id": "EZCifwcOvXPD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwIa6skfvge2",
        "outputId": "187810cc-a66b-45eb-9e64-4dddefb85b91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_api(classifier, run=True, api_type=\"text-classification\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eurm0-_Ezhg6",
        "outputId": "b39dc23e-7109-4147-cc65-dd57980b4072"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [370]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [370]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<chitra.serve.api.API at 0x7fae3aeb4390>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from transformers import pipeline\n",
        "from chitra.serve import create_api\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "cr_api = create_api(classifier, run=False, api_type=\"text-classification\")\n",
        "cr_api.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsVpH5tO69A2",
        "outputId": "1276dea9-b39e-4eb0-fe5f-8308c7f47478"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "subprocess.Popen([\"python\", \"app.py\"]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLx103uY7MtR",
        "outputId": "9e5b2ba2-e350-48d9-b66a-c39343e0bc65"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<subprocess.Popen at 0x7fae3a98c310>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! npx localtunnel --port 8000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEluBXtA4UwN",
        "outputId": "2511d97a-33ec-41a3-d9f3-e829ca1485c0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.896s\n",
            "your url is: https://serious-panda-82.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eQa8uA0B5SbP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}